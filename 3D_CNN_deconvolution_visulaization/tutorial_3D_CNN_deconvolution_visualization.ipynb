{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tf_cnnvis import *\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import gen_nn_ops\n",
    "IMG_SIZE_PX = 128\n",
    "SLICE_COUNT = 28\n",
    "\n",
    "n_classes = 2\n",
    "batch_size = 1\n",
    "# test_data = np.load('D:/NORMvsSAH/Data/NORM&SAH_Data_Folds/Fold1/Test.npy')#for 50\n",
    "# test_data = test_data[10:11]\n",
    "test_data = np.load('D:/NORMvsSAH/Data/224/Fold1/Check224.npy')####For 224\n",
    "test_data = test_data [0:1]\n",
    "@ops.RegisterGradient(\"Customlrn\")\n",
    "def _CustomlrnGrad(op, grad):\n",
    "    return grad\n",
    "@ops.RegisterGradient(\"GuidedRelu\")\n",
    "def _GuidedReluGrad(op, grad):\n",
    "    return tf.where(grad > 0.0, gen_nn_ops.relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-90177ae0f7e1>:77: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# @ops.RegisterGradient(\"GuidedRelu\")\n",
    "# def _GuidedReluGrad(op, grad):\n",
    "#     return tf.where(grad > 0.0, gen_nn_ops.relu_grad(grad, op.outputs[0]), tf.zeros(grad.get_shape()))\n",
    "\n",
    "session = tf.Session()\n",
    "eval_graph = tf.Graph()\n",
    "with eval_graph.as_default():\n",
    "    with eval_graph.gradient_override_map({'Relu': 'GuidedRelu'}):\n",
    "        x = tf.placeholder('float')\n",
    "        y = tf.placeholder('float')\n",
    "        keep_rate = 1    \n",
    "        Input = tf.reshape(x, [1, SLICE_COUNT, IMG_SIZE_PX, IMG_SIZE_PX, 1])\n",
    "\n",
    "        with tf.name_scope('Conv1'):\n",
    "            Filter1 = tf.get_variable(name='Filter1', shape=[3,3,3,1,32]) \n",
    "            Bias1 = tf.get_variable(name='Bias1', shape=[32]) \n",
    "            conv1 = tf.nn.conv3d(input = Input,filter = Filter1,strides=[1, 1, 1, 1, 1],padding='SAME')\n",
    "            Conv1 = tf.nn.relu(conv1 + Bias1)\n",
    "    #     print(\"Conv1 = \", Conv1.get_shape())\n",
    "    #######LAYER 2 CONV2 =============================================================\n",
    "\n",
    "    #######LAYER 2 POOL2 =============================================================\n",
    "        with tf.name_scope('Pool1'):\n",
    "            Pool1 = tf.nn.max_pool3d(input = Conv1,  ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        #         print(\"Conv1 = \", Conv1.get_shape())\n",
    "\n",
    "    ######LAYER 3 CONV3 =============================================================\n",
    "        with tf.name_scope('conv2'):\n",
    "            Filter2 = tf.get_variable(name='Filter2', shape=[3,3,3,32,64])\n",
    "            Bias2 = tf.get_variable(name='Bias2', shape=[64])\n",
    "            conv2 = tf.nn.conv3d(input = Pool1, filter = Filter2, \n",
    "                            strides=[1, 1, 1, 1, 1], \n",
    "                            padding='SAME')\n",
    "            Conv2 = tf.nn.relu(conv2 + Bias2)  \n",
    "    #     print(\"Conv1 = \", Conv1.get_shape())\n",
    "        with tf.name_scope('Pool2'):\n",
    "            Pool2 = tf.nn.max_pool3d(input = Conv2, \n",
    "                         ksize=[1, 2, 2, 2, 1],\n",
    "                         strides=[1, 2, 2, 2, 1], \n",
    "                         padding='SAME')   \n",
    "    #######LAYER 4 CONV4 =============================================================\n",
    "        with tf.name_scope('conv3'):\n",
    "            Filter3 = tf.get_variable(name='Filter3', shape=[3,3,3,64,128])\n",
    "            Bias3 = tf.get_variable(name='Bias3', shape=[128]) \n",
    "            conv3 = tf.nn.conv3d(input = Pool2, \n",
    "                            filter = Filter3, \n",
    "                            strides=[1, 1, 1, 1, 1], \n",
    "                            padding='SAME')\n",
    "            Conv3 = tf.nn.relu(conv3 + Bias3) \n",
    "#     print(\"Conv1 = \", Conv1.get_shape())\n",
    "    #######LAYER 4 POOL4 =============================================================\n",
    "        with tf.name_scope('Pool3'):\n",
    "            Pool3 = tf.nn.max_pool3d(input = Conv3, \n",
    "                         ksize=[1, 2, 2, 2, 1],\n",
    "                         strides=[1, 2, 2, 2, 1], \n",
    "                         padding='SAME')\n",
    "     #     print(\"Conv1 = \", Conv1.get_shape())\n",
    "    \n",
    "        with tf.name_scope('fc1') as scope:\n",
    "            FilterFc1 = tf.get_variable(name='FilterFc1', shape=[131072, 1024]) #for 224-401408 and for 50-25088 and\n",
    "            BiasFc1 = tf.get_variable(name='BiasFc1', shape=[1024])             # for 128- 131072\n",
    "            FlatFc1 = tf.reshape(Pool3, [-1,131072])  \n",
    "            OutFc1 = tf.nn.relu(tf.matmul(FlatFc1, FilterFc1) + BiasFc1)\n",
    "            DropOutFc1 = tf.nn.dropout(OutFc1, keep_rate)\n",
    "# print(\"Conv1 = \", Conv1.get_shape())\n",
    "        with tf.name_scope('Out') as scope:\n",
    "            FilterFc2 = tf.get_variable(name='FilterFc2', shape=[1024, n_classes])\n",
    "            BiasFc2 = tf.get_variable(name='BiasFc2', shape=[n_classes])\n",
    "            prediction = tf.matmul(DropOutFc1, FilterFc2) + BiasFc2    \n",
    "#     print(\"Conv1 = \", Conv1.get_shape())\n",
    "    \n",
    "\n",
    "\n",
    "        with tf.name_scope('Loss'):\n",
    "            cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) ) \n",
    "        with tf.name_scope('SGD'):\n",
    "            optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost) \n",
    "            init = tf.global_variables_initializer()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/NORMvsSAH/Metadata/128/Layer3264128/Fold1/Threshold/70/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# saver = tf.train.Saver()       \n",
    "\n",
    "outn = []\n",
    "with tf.Session(graph=eval_graph) as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "#     saver.restore(sess, \"D:/NORMvsSAH/Metadata/224/Layer3264128/Fold1/model.ckpt\")  #  for 224\n",
    "#     saver.restore(sess, \"D:/NORMvsSAH/MetaData/Layer3264128/Fold1/Threshold/model.ckpt\") # for 50\n",
    "    saver.restore(sess, \"D:/NORMvsSAH/Metadata/128/Layer3264128/Fold1/Threshold/70/model.ckpt\") # for 128    \n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    probabilities = tf.nn.softmax(prediction)\n",
    "    activation=[]\n",
    "    \n",
    "    op_tensor =  Pool1\n",
    "    \n",
    "    for data in test_data:\n",
    "        img = data[0][0]/255\n",
    "        img[img<.35]=0                \n",
    "        img_ind = 1\n",
    "        x = x\n",
    "        \n",
    "        feed_dict ={x:  img}\n",
    "#         op_tensor =  Conv1\n",
    "        activation=(sess.run(op_tensor, feed_dict = feed_dict))\n",
    "\n",
    "        print('op_tensor',np.shape(op_tensor))\n",
    "        print('activation',np.shape(activation))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from D:/NORMvsSAH/Metadata/128/Layer3264128/Fold1/Threshold/70/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# saver = tf.train.Saver()       \n",
    "\n",
    "outn = []\n",
    "with tf.Session(graph=eval_graph) as sess:\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()\n",
    "#     saver.restore(sess, \"D:/NORMvsSAH/Metadata/224/Layer3264128/Fold1/model.ckpt\")  #  for 224\n",
    "#     saver.restore(sess, \"D:/NORMvsSAH/MetaData/Layer3264128/Fold1/Threshold/model.ckpt\") # for 50\n",
    "    saver.restore(sess, \"D:/NORMvsSAH/Metadata/128/Layer3264128/Fold1/Threshold/70/model.ckpt\") # for 128    \n",
    "    correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    probabilities = tf.nn.softmax(prediction)\n",
    "    for data in test_data:\n",
    "        img = data[0][0]/255\n",
    "        img[img<.35]=0        \n",
    "        img_ind = 1\n",
    "        x = x\n",
    "        out=[]\n",
    "        feed_dict ={x:  img}\n",
    "        op_tensor =  Conv3\n",
    "        activation = sess.run(op_tensor, feed_dict = feed_dict)\n",
    "        for i in range(4):\n",
    "            activation = np.sum(activation, axis=0)\n",
    "        inds = np.argpartition(activation, -4)[-4:]\n",
    "        tensor_shape = op_tensor.get_shape().as_list()\n",
    "        \n",
    "        for ind in inds:\n",
    "            reconstruct = [tf.gradients(tf.transpose(tf.transpose(op_tensor[:,:, :, :, ind])), x)[0] ]\n",
    "            outn.extend(sess.run(reconstruct, feed_dict = feed_dict))\n",
    "        \n",
    "        print('op_tensor',np.shape(op_tensor))\n",
    "        print('activation',np.shape(activation))\n",
    "        print('inds',inds)\n",
    "        print('outn',np.shape(outn))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######For ACTIVATION VISUALIZATION\n",
    "from matplotlib.pyplot import imsave\n",
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "cmap = plt.cm.bone\n",
    "from math import ceil, sqrt\n",
    "# from scipy.misc import imsave\n",
    "from matplotlib.pyplot import imsave\n",
    "\n",
    "activationx=activation[0][7].reshape(1,112,112,32)\n",
    "act_shape = np.shape(activationx)\n",
    "activations = activationx\n",
    "\n",
    "act_shape\n",
    "if len(act_shape) == 2:\n",
    "    grid_activations = [np.expand_dims(image_normalization(convert_into_grid(im[:,np.newaxis,np.newaxis,np.newaxis], padding=0)), axis = 0) for im in activations]\n",
    "else:\n",
    "    activations = [np.expand_dims(im, axis = 3) for im in np.transpose(activations, (3, 0, 1, 2))]\n",
    "    activations = _im_normlize(activations)\n",
    "    grid_activations = _images_to_grid(activations)\n",
    "for i in range(len(grid_activations)):\n",
    "    imsave(( \"D:/actn_vis.png\"), grid_activations[i][0,:,:,0], format = \"png\", cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######For DECONV VISUALIZATION\n",
    "from matplotlib.pyplot import imsave\n",
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "out=[]\n",
    "cmap = plt.cm.bone\n",
    "for i in range(len(outn)):\n",
    "    im=outn[i][14]\n",
    "#     backtorgb = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)    \n",
    "    out.append(im.reshape(1,IMG_SIZE_PX,IMG_SIZE_PX,1))\n",
    "images = _im_normlize(out)\n",
    "grid_images = _images_to_grid(images)\n",
    "for i in range(len(grid_images)):\n",
    "    if grid_images[i].shape[-1] == 1:\n",
    "        imsave((\"D:/DECO_Vis.png\"), grid_images[i][0,:,:,0], format = \"png\", cmap=cmap)\n",
    "        plt.imshow(grid_images[i][0,:,:,0],cmap=cmap )\n",
    "        plt.show()\n",
    "#         imsave((\"D:/DECO_Vis.png\"), grid_images[i][0,:,:,0], format = \"png\")\n",
    "    else:\n",
    "        imsave(( \"D:/DECO_Vis.png\"), grid_images[i][0], format = \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 112, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(activation[0][7].reshape(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
